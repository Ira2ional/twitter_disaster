{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62AwUJIei_WK"
      },
      "source": [
        "#               **Twitter Disaster Challenge**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The main idea of this task it's how we can classify twitter disaster messages.\n",
        "\n",
        "I've developed several approaches to solve this problem and analyze the data.\n",
        "\n",
        "I wanted to focus on how we can work with the data and how it will affect the results, because I think this is the interesting part.\n",
        "Therefore, in my approach, I did not remove hashtags from the text and use neural networks.\n",
        "\n",
        "First of all, it's features engineering approach: I've analyzed the data and created new features using hashtags and keywords from text messages.\n",
        "\n",
        "After that, I used embedding approaches (tf-idf and word2vec) to create vectorize.\n",
        "\n",
        "For both embedding approaches, I've applied SVM, Support Vector Classifier trained with Stochastic Gradient Descent, Naive Bayes, Decision Tree, and Random Forest to classify.\n",
        "\n",
        "Moreover, I've used precision, recall, score metrics to evaluate the model's results."
      ],
      "metadata": {
        "id": "cdiWXDMC_AZG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtDbuFr-i6VU"
      },
      "source": [
        "## Library implementation and download the data (using GDrive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xObnsN-m_L4H",
        "outputId": "42d93df0-ac05-4b30-b9b5-c2f15903cf99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (2.5.3)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: fastcore<1.4,>=1.3.22 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.27)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (21.3)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (21.1.3)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.11.1+cu111)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied: torch<1.11,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.10.0+cu111)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fastprogress>=0.2.4->fastai) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (57.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (0.9.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install -U fastai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XemZkEpi6jl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torch.nn.functional import cosine_similarity\n",
        "from torchvision import models, transforms\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from fastai.text.all import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S87105aFcIQ2",
        "outputId": "9bc76667-4c7d-4f6b-eac9-03b723485f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA9Q8REIiLr6",
        "outputId": "6e276510-a1d6-4a89-a50b-8b02879e223d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/MyDrive/apli_challenge.zip\n",
            "replace apli_challenge/APLI CHALLENGE/train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip /content/gdrive/MyDrive/apli_challenge.zip -d apli_challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVdjQFqGcJFP"
      },
      "outputs": [],
      "source": [
        "test_path = '/content/apli_challenge/APLI CHALLENGE/test.csv'\n",
        "train_path = '/content/apli_challenge/APLI CHALLENGE/train.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw4kNT20cJHv",
        "outputId": "1141d370-1ac5-4655-9b89-023f72d298a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7d0zXfojmMY"
      },
      "source": [
        "## Data analysis part\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMce5PN1xQX8"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(test_path)\n",
        "train_df = pd.read_csv(train_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olKostczcJNA",
        "outputId": "868fdd18-a1db-4070-a0cb-1b3dc05cc39a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7613, 5), (3263, 5))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "PKMdoY3jnsbz",
        "outputId": "adb38d2f-34ae-4f3e-c114-dc04073449fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d2cc7fd7-6450-4469-9dbc-bcb1f3c9bbbc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2cc7fd7-6450-4469-9dbc-bcb1f3c9bbbc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2cc7fd7-6450-4469-9dbc-bcb1f3c9bbbc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2cc7fd7-6450-4469-9dbc-bcb1f3c9bbbc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  ... target\n",
              "0   1  ...      1\n",
              "1   4  ...      1\n",
              "2   5  ...      1\n",
              "3   6  ...      1\n",
              "4   7  ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOZLrs1xdMR4",
        "outputId": "7743fc32-fcce-4419-b4be-bf3336fa0082"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                                                                           Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
              "1                                                                                                          Forest fire near La Ronge Sask. Canada\n",
              "2           All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
              "3                                                                               13,000 people receive #wildfires evacuation orders in California \n",
              "4                                                        Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \n",
              "                                                                          ...                                                                    \n",
              "7608                                                          Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5\n",
              "7609                @aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.\n",
              "7610                                                                            M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ\n",
              "7611    Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.\n",
              "7612                                               The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d\n",
              "Name: text, Length: 7613, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "vlmbxdUxrS0B",
        "outputId": "1f3e07bf-a985-4e3e-aacf-5b196fd9e369"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3b735f6a-0937-4632-81ac-15783ced65a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>48</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>Birmingham</td>\n",
              "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>49</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>Est. September 2012 - Bristol</td>\n",
              "      <td>We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>50</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>AFRICA</td>\n",
              "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>52</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>Philadelphia, PA</td>\n",
              "      <td>Crying out for more! Set me ablaze</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>53</td>\n",
              "      <td>ablaze</td>\n",
              "      <td>London, UK</td>\n",
              "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7578</th>\n",
              "      <td>10830</td>\n",
              "      <td>wrecked</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@jt_ruff23 @cameronhacker and I wrecked you both</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7579</th>\n",
              "      <td>10831</td>\n",
              "      <td>wrecked</td>\n",
              "      <td>Vancouver, Canada</td>\n",
              "      <td>Three days off from work and they've pretty much all been wrecked hahaha shoutout to my family for that one</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7580</th>\n",
              "      <td>10832</td>\n",
              "      <td>wrecked</td>\n",
              "      <td>London</td>\n",
              "      <td>#FX #forex #trading Cramer: Iger's 3 words that wrecked Disney's stock http://t.co/7enNulLKzM</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7581</th>\n",
              "      <td>10833</td>\n",
              "      <td>wrecked</td>\n",
              "      <td>Lincoln</td>\n",
              "      <td>@engineshed Great atmosphere at the British Lion gig tonight. Hearing is wrecked. http://t.co/oMNBAtJEAO</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7582</th>\n",
              "      <td>10834</td>\n",
              "      <td>wrecked</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Cramer: Iger's 3 words that wrecked Disney's stock - CNBC http://t.co/N6RBnHMTD4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7552 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b735f6a-0937-4632-81ac-15783ced65a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3b735f6a-0937-4632-81ac-15783ced65a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3b735f6a-0937-4632-81ac-15783ced65a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         id  ... target\n",
              "31       48  ...      1\n",
              "32       49  ...      0\n",
              "33       50  ...      1\n",
              "34       52  ...      0\n",
              "35       53  ...      0\n",
              "...     ...  ...    ...\n",
              "7578  10830  ...      0\n",
              "7579  10831  ...      0\n",
              "7580  10832  ...      0\n",
              "7581  10833  ...      0\n",
              "7582  10834  ...      0\n",
              "\n",
              "[7552 rows x 5 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[~train_df['keyword'].isnull()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM5sfcaZucBk",
        "outputId": "5b2b526a-0df1-4c13-be4c-acf788a750c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
              "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
              "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
              "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
              "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
              "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
              "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
              "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
              "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
              "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
              "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
              "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
              "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
              "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
              "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
              "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
              "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
              "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
              "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
              "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
              "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
              "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
              "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
              "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
              "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
              "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
              "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
              "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
              "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
              "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
              "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
              "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
              "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
              "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
              "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
              "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
              "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
              "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
              "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
              "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
              "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
              "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
              "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
              "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
              "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
              "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['keyword'].unique() # look at the unique 'keyword' values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "9nAjMf3jny4l",
        "outputId": "f8da549c-b09f-4a12-ebdb-8ac11900a872"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c235ecee-09ec-4411-a734-3e57713c0c61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, stay safe everyone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are fleeing across the street, I cannot save them all</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c235ecee-09ec-4411-a734-3e57713c0c61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c235ecee-09ec-4411-a734-3e57713c0c61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c235ecee-09ec-4411-a734-3e57713c0c61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  ... target\n",
              "0   0  ...      1\n",
              "1   2  ...      1\n",
              "2   3  ...      1\n",
              "3   9  ...      1\n",
              "4  11  ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head() # we can see that  in 'text' column we have text with hash tag sign('#') and some url's."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klZEq0IQlQzE",
        "outputId": "9880654b-5104-4ff3-b292-9993af175787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        7613 non-null   int64 \n",
            " 1   keyword   7552 non-null   object\n",
            " 2   location  5080 non-null   object\n",
            " 3   text      7613 non-null   object\n",
            " 4   target    7613 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 297.5+ KB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRvNCKQ3lkbY",
        "outputId": "018726a2-1d2c-449f-d461-6973869e0115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3263 entries, 0 to 3262\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        3263 non-null   int64 \n",
            " 1   keyword   3237 non-null   object\n",
            " 2   location  2158 non-null   object\n",
            " 3   text      3263 non-null   object\n",
            " 4   target    3263 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 127.6+ KB\n"
          ]
        }
      ],
      "source": [
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4Fd5J3YlmbT",
        "outputId": "2aa6576d-670c-49f4-b6d9-e42996942e70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.57034\n",
              "1    0.42966\n",
              "Name: target, dtype: float64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df[\"target\"].value_counts()/train_df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWMWntPnYN3I"
      },
      "source": [
        "## Feature extraction part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4QOmM0vfH-C"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOpJC8R5x2td"
      },
      "source": [
        "### Hashtag approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL7gsfFDeusY"
      },
      "outputs": [],
      "source": [
        "# get the hashtags set with the hashtags that appear in the text more then \"level\" times\n",
        "def find_hashtags(train_df, level=0): \n",
        "    train_df['text'] = train_df['text'].apply(lambda x: x.lower()) #map all the text to lowercase\n",
        "    train_df[\"tag\"] = train_df[\"text\"].apply(lambda x: re.findall(r\"#(\\w+)\", x)) #find all of the hashtags\n",
        "    tags=set([]) \n",
        "    for loc_tags in train_df[\"tag\"]: \n",
        "        for tag in loc_tags:\n",
        "            if not (tag is None):\n",
        "                train_df[tag]=train_df[\"text\"].apply(lambda x: int(\"#\"+tag in x))\n",
        "                if train_df[tag].sum()>level:\n",
        "                    tags.add(tag)\n",
        "                del train_df[tag]\n",
        "    del train_df[\"tag\"]\n",
        "    return tags\n",
        "\n",
        "#we get extra features for the dataset, that illustrated does the specific hashtag belong to the text\n",
        "def to_hashtags(train, tags):\n",
        "    for tag in tags:\n",
        "        train[tag]=train[\"text\"].apply(lambda x: int(\"#\"+tag in x))\n",
        "    train[\"text\"]=train[\"text\"].apply(lambda x: x.replace(\"#\", \"\"))\n",
        "    del train[\"text\"]\n",
        "    del train[\"location\"]\n",
        "    del train[\"keyword\"]\n",
        "    del train[\"id\"]\n",
        "    return train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSFEEbAqYNR2",
        "outputId": "4bfccc25-4401-448c-ed92-22b2270af07a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
          ]
        }
      ],
      "source": [
        "#now just load data get the hashtags and try to figure can the hashtags alone give the information about markup\n",
        "tags = find_hashtags(train_df)\n",
        "train_df = to_hashtags(train_df, tags) \n",
        "#right here we get the embedding of 0 and 1 where the text either contains the hashtag or not\n",
        "test_df = to_hashtags(test_df, tags)\n",
        "#N.B. note, that we use the same \"tags\" set for the test sample, since we got to get the embedding\n",
        "#into the same space. We do not find the tags for the test data.\n",
        "\n",
        "train_target = train_df[\"target\"]\n",
        "train_features = train_df.copy() # here we use copy method not to change the \"train_df\" itself during processing\n",
        "del train_features[\"target\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_target, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bga-YYnAf9Ag"
      },
      "source": [
        "#### Support Vector Classifier for hashtag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFylF66NfvU2",
        "outputId": "dcc83615-e253-4ac9-bca9-e9a57b89e4c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6014445173998687\n",
            "(array([0.97142857, 0.10185185]), array([0.59357542, 0.72527473]), array([0.73688773, 0.17861976]), array([1432,   91]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw2cybm4gT8s"
      },
      "source": [
        "#### Support Vector Classifier trained with Stochastic Gradient Descent for hashtag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr-K1tuFgOwc",
        "outputId": "e0694179-ba49-4e1b-a715-1ea3e2811287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6047275114904793\n",
            "(array([0.95085714, 0.13734568]), array([0.59813084, 0.67424242]), array([0.73433363, 0.22820513]), array([1391,  132]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "model = SGDClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dStoEb6lgaqu"
      },
      "source": [
        "#### Naive Bayes for hashtag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ir_S_cofgPGQ",
        "outputId": "77ece074-85bb-4267-bf10-7787130ad121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6066973079448457\n",
            "(array([0.95428571, 0.13734568]), array([0.5989957 , 0.68992248]), array([0.73600705, 0.22908623]), array([1394,  129]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB \n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldTX0XHkgwbO"
      },
      "source": [
        "### Keywords approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGjl67LOiBkn"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(test_path)\n",
        "train = pd.read_csv(train_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIKHxW7aih6q"
      },
      "outputs": [],
      "source": [
        "def find_keywords(train, level=0):\n",
        "    train[\"keyword\"] = train[\"keyword\"].apply(lambda x: str(x).lower().split(\",\"))\n",
        "    keywords=set([])\n",
        "    for loc_keywords in train[\"keyword\"]:\n",
        "        for keyword in loc_keywords:\n",
        "            if not (keyword == \"nan\"):\n",
        "                train[keyword]=train[\"keyword\"].apply(lambda x: int(keyword in x))\n",
        "                if train[keyword].sum()>level:\n",
        "                    keywords.add(keyword)\n",
        "                del train[keyword]\n",
        "    return keywords\n",
        "\n",
        "def to_keywords(train, keywords):\n",
        "    train[\"keyword\"] = train[\"keyword\"].apply(lambda x: str(x).lower().split(\",\"))\n",
        "    for keyword in keywords:\n",
        "        train[keyword]=train[\"keyword\"].apply(lambda x: int(keyword in x))\n",
        "    del train[\"text\"]\n",
        "    del train[\"location\"]\n",
        "    del train[\"id\"]\n",
        "    del train[\"keyword\"]\n",
        "    return train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhlT23rQntYm",
        "outputId": "9be0f251-3fae-4619-c43c-19260b70bf47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ],
      "source": [
        "keywords = find_keywords(train)\n",
        "train_df = to_keywords(train, keywords)\n",
        "test_df = to_keywords(test, keywords)\n",
        "\n",
        "\n",
        "\n",
        "train_target = train_df[\"target\"]\n",
        "train_features = train_df.copy()\n",
        "del train_features[\"target\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_target, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u24BvquEm3-6"
      },
      "source": [
        "#### Support Vector Classifier for keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6Gd--CFnwW8",
        "outputId": "a98e12cc-633f-45cc-af6b-a78adef17243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5633617859487853\n",
            "(array([1., 0.]), array([0.56336179, 0.        ]), array([0.72070559, 0.        ]), array([1523,    0]))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B64AHZDqm6EW"
      },
      "source": [
        "#### Support Vector Classifier trained with Stochastic Gradient Descent for keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTneGLVenzGj",
        "outputId": "0343c707-eee9-4b32-eced-4607a6a12c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5633617859487853\n",
            "(array([1., 0.]), array([0.56336179, 0.        ]), array([0.72070559, 0.        ]), array([1523,    0]))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "model = SGDClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8EraKDZm6G1"
      },
      "source": [
        "#### Naive Bayes for keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyVxiYhrgFzm",
        "outputId": "3e529eb7-7aa2-4d4e-ab09-a6b237a119ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5633617859487853\n",
            "(array([1., 0.]), array([0.56336179, 0.        ]), array([0.72070559, 0.        ]), array([1523,    0]))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB \n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8xDaaskn7ot"
      },
      "source": [
        "So, we got it, about 0.6. Surely, you can try to concatenate the embeddings of the keywords and hashtags, and even add it to the text embedding, they can get the more accurate classification, but still do not work alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNKPN_tYl9fh"
      },
      "source": [
        "## Data processing part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4cRVjWnuJn5"
      },
      "source": [
        "### TF-IDF vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M9wQwElojqV"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK4b4EVtsirH",
        "outputId": "6524b1e7-ab55-4088-af0f-3067e0b7e182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG-XSE0kojsx"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(test_path)\n",
        "train = pd.read_csv(train_path)\n",
        "train[\"text\"] = train[\"text\"].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CMcqdwFoju9",
        "outputId": "f2134f32-8797-41f6-9133-af75772e0cb8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "stopWords = set(stopwords.words('english')) \n",
        "for w in stopWords:\n",
        "    train[\"text\"] = train[\"text\"].apply(lambda x: x.replace(\" \"+w+\" \", \" \"))\n",
        "\n",
        "vectorizer = TfidfVectorizer() #use the TF-IDF model for text embedding\n",
        "\n",
        "train[\"text\"] =train[\"text\"].apply(lambda x: x.replace(\"#\",\"\")) \n",
        "\n",
        "tfidf_train = vectorizer.fit_transform(train[\"text\"])\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#The problem is that the dimention of the text embedding in TF-IDF model or BOW model is too large, \n",
        "#so we got to reduce the dimentionality, thus, we try to make some\n",
        "#feature as the Principal Component Analysis.\n",
        "\n",
        "pca = PCA(n_components=500)\n",
        "lower_dim_tfidf_train = pca.fit_transform(tfidf_train.todense())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQMXEoUEs0XZ"
      },
      "outputs": [],
      "source": [
        "train_df = lower_dim_tfidf_train\n",
        "train_target = train[\"target\"]\n",
        "train_features = train_df.copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_target, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXkJQXY8stB6"
      },
      "source": [
        "#### SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvc7F3j8srJt",
        "outputId": "03bc1b6d-8799-4e37-de96-26a948c92000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7957977675640184\n",
            "(array([0.90437788, 0.6519084 ]), array([0.77492596, 0.8372549 ]), array([0.83466241, 0.73304721]), array([1013,  510]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs3xJZzPs532"
      },
      "source": [
        "#### SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc4eYPrFsrMZ",
        "outputId": "f8cc7d3c-643e-4f30-f491-f1ed71679d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7898883782009193\n",
            "(array([0.89516129, 0.65038168]), array([0.77236581, 0.82398453]), array([0.82924226, 0.72696246]), array([1006,  517]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "model = SGDClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l48olwktCu3"
      },
      "source": [
        "#### Decision Tree\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ey4JFwZktDDD",
        "outputId": "3976f5f1-1d4b-475f-9a6f-6ffce5ccb6ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6979645436638214\n",
            "(array([0.73041475, 0.65496183]), array([0.7372093 , 0.64705882]), array([0.7337963 , 0.65098634]), array([860, 663]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier \n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm2_3f_jsr92"
      },
      "source": [
        "#### RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5CueS5xojxo",
        "outputId": "bf32ebf3-1583-4584-bdad-e853a2be772e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.778069599474721\n",
            "(array([0.91359447, 0.59847328]), array([0.75094697, 0.83940043]), array([0.82432432, 0.69875223]), array([1056,  467]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier  #here we add Random Forest Classifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IycZ0BLCpHwS"
      },
      "source": [
        "### Word2Vec embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DEJeARx30oa"
      },
      "outputs": [],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPT_n4wYoj0D"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(test_path)\n",
        "train = pd.read_csv(train_path)\n",
        "some_texts = train[\"text\"].apply(lambda x: x.lower()).apply(lambda x: x.replace(\"#\",\"\"))\n",
        "\n",
        "stopWords = set(stopwords.words('english'))\n",
        "\n",
        "for w in stopWords:\n",
        "    some_texts = some_texts.apply(lambda x: x.replace(\" \"+w+\" \", \" \"))\n",
        "\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(some_texts)]\n",
        "\n",
        "model = Doc2Vec(documents, vector_size=1000, workers=4, epochs=50)\n",
        "textdf = model.docvecs\n",
        "\n",
        "train_target = train[\"target\"]\n",
        "train_features = textdf\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_target, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG_GnD5uufgF"
      },
      "source": [
        "#### SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6wHt8wwoj2j",
        "outputId": "66d9c0d9-4c8f-4473-9001-fdcc949d30b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6710439921208142\n",
            "(array([0.80280047, 0.5015015 ]), array([0.6745098, 0.6640159]), array([0.73308471, 0.57142857]), array([1020,  503]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LIJ6Gqmug0R"
      },
      "source": [
        "#### SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY5-gql1uvJT",
        "outputId": "5680b8c0-d406-4b1f-8681-2084e8980f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.639527248850952\n",
            "(array([0.65344224, 0.62162162]), array([0.68965517, 0.58227848]), array([0.67106052, 0.60130719]), array([812, 711]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "model = SGDClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTBBuKWRug3D"
      },
      "source": [
        "#### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xoIFyQaZoj45",
        "outputId": "357f0c2c-3189-48da-b139-9c9029ce8425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5732107682206172\n",
            "(array([0.62193699, 0.51051051]), array([0.62048894, 0.51204819]), array([0.62121212, 0.5112782 ]), array([859, 664]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjrgnuM0vET9"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qp0DbgYwoj7W",
        "outputId": "a96d0236-ed72-41f8-f0c0-613f0b79d955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.670387393302692\n",
            "(array([0.78996499, 0.51651652]), array([0.67767768, 0.65648855]), array([0.72952586, 0.57815126]), array([999, 524]))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "print(model.score(X_test, y_test))\n",
        "print(precision_recall_fscore_support(model.predict(X_test), y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Twitter_Disaster_Challenge.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}